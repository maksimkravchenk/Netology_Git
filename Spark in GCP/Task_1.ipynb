{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3973802d-542d-47d8-9efc-fe25570cc115",
   "metadata": {},
   "source": [
    "### Разработайте задачу, записывающую данные из BigQuery в GCS, и запустите ее на задеплоенном кластере Dataproc. Приведите код задачи и скриншот выгрузки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec98517-e126-4b44-97a4-99501f677bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peaceful-parity-336514-f361713c806a.json\n",
      "peaceful-parity-336514\n",
      "<google.oauth2.service_account.Credentials object at 0x0000019273819880>\n"
     ]
    }
   ],
   "source": [
    "#Create Google cloud bucket\n",
    "from google.cloud import storage\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# this is the path to the key file which you get from the GCP \n",
    "key_path = \"C:\\\\Users\\\\peaceful-parity-336514-f361713c806a.json\"\n",
    "print(key_path)\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")\n",
    "print(credentials.project_id)\n",
    "print(credentials)\n",
    "\n",
    "storage_client = storage.Client(credentials=credentials, project=credentials.project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf90ad09-ca5d-40c0-a572-9550fa251cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The name for the new bucket\n",
    "bucket_name = \"dataproc_lab_bucket\"\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "bucket.storage_class = \"STANDARD\"\n",
    "new_bucket = storage_client.create_bucket(bucket, location = \"us\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905717c2-0ca6-4ea0-ba7e-96d12e788f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate SparkSession to the DataProc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8dd202-d402-4489-b829-785529b2d4d0",
   "metadata": {},
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "\n",
    "\"\"\"BigQuery I/O PySpark example.\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "  .builder \\\n",
    "  .master('yarn') \\\n",
    "  .appName('spark-bigquery-demo') \\\n",
    "  .getOrCreate()\n",
    "\n",
    "# Use the Cloud Storage bucket for temporary BigQuery export data used\n",
    "# by the connector.\n",
    "bucket = \"[bucket]\"\n",
    "spark.conf.set('temporaryGcsBucket', bucket)\n",
    "\n",
    "# Load data from BigQuery.\n",
    "words = spark.read.format('bigquery') \\\n",
    "  .option('table', 'bigquery-public-data:samples.shakespeare') \\\n",
    "  .load()\n",
    "words.createOrReplaceTempView('words')\n",
    "\n",
    "# Perform word count.\n",
    "word_count = spark.sql(\n",
    "    'SELECT word, SUM(word_count) AS word_count FROM words GROUP BY word')\n",
    "word_count.show()\n",
    "word_count.printSchema()\n",
    "\n",
    "# Saving the data to BigQuery\n",
    "word_count.write.format('bigquery') \\\n",
    "  .option('table', 'wordcount_dataset.wordcount_output') \\\n",
    "  .save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad2613-5812-41b2-9079-167c39438d0d",
   "metadata": {},
   "source": [
    "# Code example on the GCP Jupyter notebook\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Lab_dataProc\") \\\n",
    "    .config(\"spark.jars\",\"gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "bq_df = spark.read.format(\"bigquery\").option(\"table\",\"bigquery-public-data:google_books_ngrams_2020.rus_1\").load()\n",
    "\n",
    "bq_df.printSchema()\n",
    "\n",
    "bq_df.write \\\n",
    "    .format(\"parquet\")\\\n",
    "    .mode(\"overwrite\")\\\n",
    "    .save(\"gs://dataproc_lab_bucket/dataproc_lab\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
