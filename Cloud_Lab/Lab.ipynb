{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d60cdcc-b0a1-4828-9156-424e0ce28b2f",
   "metadata": {},
   "source": [
    "# Задание\n",
    "    конфигурируем окружение\n",
    "    создаем Dataproc (Spark-кластер)\n",
    "    загружаем датасет (Credit Card Default)\n",
    "    копируем и анализируем данные в BigQuery\n",
    "    выгружаем в GCS в формате .parquet при помощи Dataflow, используя шаблон\n",
    "    загружаем данные при помощи Spark\n",
    "    работаем с данными через Spark SQL в Jupyter\n",
    "    Бонус:\n",
    "    работа с данными через Pandas и визуализация\n",
    "    В документе более подробное описание задания и комментарии по выполнению.\n",
    "\n",
    "    Вопросы для самопроверки:\n",
    "\n",
    "    Вывести количество верно спрогнозированных просрочек\n",
    "    Вывести медиану кредитного лимита в зависимости от возраста клиента\n",
    "    Ответы на эти вопросы (в виде выгрузки или скриншотов) нужно вложить в тред.\n",
    "    Для ответа на эти вопросы потребуется сформировать SQL-запрос(ы) и выполнить его в BigQuery и в Jupyter (Spark SQL), соответственно\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2bc6b24-4fff-499b-9fa8-76d93865ac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\peaceful-parity-336514-f361713c806a.json\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import bigquery_datatransfer\n",
    "\n",
    "# this is the path to the key file which you get from the GCP \n",
    "key_path = \"C:\\\\Users\\\\peaceful-parity-336514-f361713c806a.json\"\n",
    "print(key_path)\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    key_path, scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42a8c87f-4d78-402d-9cfe-e3cccc486ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup the GCP client. \n",
    "#Create the object of the client credentials and project_id comes from the key file \n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02677053-d9e1-4d47-806d-6a9ccea89512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset peaceful-parity-336514.GCP_lab_credit_card_dataset\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset\n",
    "dataset_name = \"GCP_lab_credit_card_dataset\"\n",
    "dataset_id = \"{}.GCP_lab_credit_card_dataset\".format(client.project, dataset_name)\n",
    "\n",
    "# Construct a full Dataset object to send to the API.\n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "\n",
    "# TODO(developer): Specify the geographic location where the dataset should reside.\n",
    "dataset.location = \"US\"\n",
    "\n",
    "# Send the dataset to the API for creation, with an explicit timeout.\n",
    "# Raises google.api_core.exceptions.Conflict if the Dataset already\n",
    "# exists within the project.\n",
    "dataset = client.create_dataset(dataset, timeout=30)  # Make an API request.\n",
    "print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e43cc91-4fda-4469-8bf2-75eaf7739f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCP_lab_credit_card_dataset\n"
     ]
    }
   ],
   "source": [
    "print(dataset.dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b901ecd-fc9f-4e7d-be41-643784b3f0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query results loaded to the table peaceful-parity-336514.GCP_lab_credit_card_dataset.Credit_card_copy\n"
     ]
    }
   ],
   "source": [
    "#Copy the table into the my project my dataset my table \n",
    "# Construct a BigQuery client object.\n",
    "# TODO(developer): Set table_id to the ID of the destination table.\n",
    "source_table_path = \"bigquery-public-data.ml_datasets.credit_card_default\"\n",
    "table_name = \"Credit_card_copy\"\n",
    "\n",
    "table_id = \"{}.{}.{}\".format(client.project,dataset.dataset_id,table_name)\n",
    "job_config = bigquery.QueryJobConfig(destination=table_id)\n",
    "\n",
    "sql = \"SELECT * FROM `{}`;\".format(source_table_path)\n",
    "\n",
    "# Start the query, passing in the extra configuration.\n",
    "query_job = client.query(sql, job_config=job_config)  # Make an API request.\n",
    "query_job.result()  # Wait for the job to complete.\n",
    "\n",
    "print(\"Query results loaded to the table {}\".format(table_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ac7f94e-4c68-4d42-94be-1a3203da0565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Model accuracy is: 78.58347386172007%\n"
     ]
    }
   ],
   "source": [
    "# Query the dataset table \n",
    "query_0 = \"\"\"\n",
    "SELECT id, default_payment_next_month, score.tables.score, score.tables.value \n",
    "FROM `{}`, unnest(predicted_default_payment_next_month) as score\n",
    "where (score.tables.score > 0.5);\n",
    "\"\"\".format(table_id)\n",
    "\n",
    "query_1 = \"\"\"\n",
    "SELECT id, default_payment_next_month, score.tables.score, score.tables.value \n",
    "FROM `{}`, unnest(predicted_default_payment_next_month) as score\n",
    "where (score.tables.score > 0.5 and default_payment_next_month = '1');\n",
    "\"\"\".format(table_id)\n",
    "\n",
    "query_0_job = client.query(query_0)  # Make an API request.\n",
    "query_1_job = client.query(query_1)  # Make an API request.\n",
    "\n",
    "result_0 = query_0_job.result()\n",
    "result_1 = query_1_job.result()\n",
    "if result_1.total_rows == 0:\n",
    "    print(\"The Model accuracy is: 100%\")\n",
    "else:\n",
    "    Accuracy = (1 - result_1.total_rows/result_0.total_rows) * 100\n",
    "    print(\"The Model accuracy is: {}%\".format(Accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba183f8-20cb-4181-96a7-46aefe09828c",
   "metadata": {},
   "source": [
    "Using the GCP Console:   \n",
    ">>    Job name:   cloudlab1  \n",
    ">>    Job region: us-central1  \n",
    ">>    goog-dataflow-provided-template-name: bigquery_to_parquet  \n",
    ">>    goog-dataflow-provided-template-type: flex  \n",
    ">>    tableRef: peaceful-parity-336514:GCP_lab_credit_card_dataset.Credit_card_copy  \n",
    ">>    bucket: gs://ml_model_lab/lab_1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "abc6cbb2-4be3-41f9-a20a-7bf5a62da96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab_1/output-00000-of-00001.parquet\n",
      "ml_lab//model.bst\n",
      "ml_lab/model.bst\n",
      "model.bst\n"
     ]
    }
   ],
   "source": [
    "# Check the result of the Dataflow\n",
    "from google.cloud import storage\n",
    "\n",
    "bucket_name = \"ml_model_lab\"\n",
    "storage_client = storage.Client(credentials=credentials, project=credentials.project_id)\n",
    "blobs = storage_client.list_blobs(bucket_name)\n",
    "for blob in blobs:\n",
    "    print(blob.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad50caf-89b3-428c-bb21-4859f9a126ec",
   "metadata": {},
   "source": [
    "# Create dataproc cluster\n",
    "gcloud dataproc clusters create cluster-cloudlab --autoscaling-policy policy-dataproc --enable-component-gateway --region us-central1 --zone us-central1-f --master-machine-type n1-standard-4 --master-boot-disk-size 500 --num-workers 2 --worker-machine-type n1-standard-4 --worker-boot-disk-size 500 --image-version 2.0-debian10 --optional-components JUPYTER --project peaceful-parity-336514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30db19a2-0c43-4a90-be13-ff0f0ab8988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scala -version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f616fe-0c1c-4503-bc7f-336ddabcc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#create spark session \n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Final_Lab\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "#load the datastore (dataset)\n",
    "datastore = \"gs://ml_model_lab/lab_1\"\n",
    "gs_df = spark.read.format(\"parquet\").load(datastore)\n",
    "\n",
    "#show the first 10 records of data \n",
    "gs_df.show(10)\n",
    "\n",
    "#print Schema\n",
    "gs_df.printSchema()\n",
    "\n",
    "#print the median of the limit_balance from age using percentile function \n",
    "gs_df.registerTempTable(\"df\")\n",
    "mdf = spark.sql(\"select age, percentile_approx(limit_balance, 0.5) as mlimit_balance from df group by age order by age\")\n",
    "mdf.show()\n",
    "\n",
    "#print the median of the limit_balance from age using sum(limit_balance(age)/count(age))\n",
    "gs_df.registerTempTable(\"df_2\")\n",
    "mdf_2 = spark.sql(\"select age, count(age) as cnt, (sum(limit_balance)/count(age)) as ave_limit_balance from df_2 group by age order by age\")\n",
    "mdf_2.show()\n",
    "\n",
    "# Test that sum and count is working for 21 age\n",
    "gs_df.registerTempTable(\"df_3\")\n",
    "mdf_3 = spark.sql(\"select age, limit_balance from df_3 where age = '21.0'\")\n",
    "mdf_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ced08b-3959-4422-bd96-5da233202fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = mdf_2.toPandas()\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b5567-5475-405c-b1d2-05855097c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.plot(\"age\", \"mlimit_balance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffdf4738-bb06-4217-8cea-15c5a4acc0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted dataset 'peaceful-parity-336514.GCP_lab_credit_card_dataset'.\n"
     ]
    }
   ],
   "source": [
    "client.delete_dataset(\n",
    "    dataset_id, delete_contents=True, not_found_ok=True\n",
    ")  # Make an API request.\n",
    "\n",
    "print(\"Deleted dataset '{}'.\".format(dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d0eae-b11f-4bfa-864f-93231914e709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
